 newp Create a perceptron.
 
  Obsoleted in R2010b NNET 7.0.  Last used in R2010a NNET 6.0.4.
 
   Syntax
 
     net = newp(p,t,tf,lf)
 
   Description
 
     Perceptrons are used to solve simple (i.e. linearly
     separable) classification problems.
 
     NET = newp(P,T,TF,LF) takes these inputs,
       P  - RxQ matrix of Q1 representative input vectors.
       T  - SxQ matrix of Q2 representative target vectors.
       TF - Transfer function, default = 'hardlim'.
       LF - Learning function, default = 'learnp'.
     Returns a new perceptron.
 
     The transfer function TF can be HARDLIM or HARDLIMS.
     The learning function LF can be LEARNP or LEARNPN.
 
   Examples
 
     This code creates a perceptron layer with one 2-element
     input (ranges [0 1] and [-2 2]) and one neuron. (Supplying
     only two arguments to newp results in the default perceptron
     learning function LEARNP being used.)
 
       net = newp([0 1; -2 2],1);
 
     Now we define a problem, an OR gate, with a set of four
     2-element input vectors  P and the corresponding four
     1-element targets T.
 
       P = [0 0 1 1; 0 1 0 1];
       T = [0 1 1 1];
 
     Here we simulate the network's output, train for a
     maximum of 20 epochs, and then simulate it again.
 
       Y = net(P)
       net.trainParam.epochs = 20;
       net = train(net,P,T);
       Y = net(P)
 
   Notes
 
     Perceptrons can classify linearly separable classes in a
     finite amount of time. If input vectors have a large variance
     in their lengths, the LEARNPN can be faster than LEARNP.
 
   Properties
 
     Perceptrons consist of a single layer with the DOTPROD
     weight function, the NETSUM net input function, and the specified
     transfer function.
 
     The layer has a weight from the input and a bias.
 
     Weights and biases are initialized with INITZERO.
 
     Adaption and training are done with TRAINS and TRAINC,
     which both update weight and bias values with the specified
     learning function.  Performance is measured with MAE.
 
   See also sim, init, adapt, train, hardlim, hardlims, learnp, learnpn, trainb, trains.
